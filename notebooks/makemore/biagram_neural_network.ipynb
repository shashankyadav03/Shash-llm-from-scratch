{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r')\n",
    "words = words.readlines()\n",
    "words = [word.strip() for word in words]\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each small alphabet to a number\n",
    "stoi = {chr(i): i - 96 for i in range(97, 123)}\n",
    "stoi = {**stoi, '.': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {v: k for k, v in stoi.items()}\n",
    "itos[0] = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs , ys = [], []\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1, ix2 = stoi[ch1], stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs), len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsenc = F.one_hot(xs, num_classes=len(stoi)).float()\n",
    "xsenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x141c97080>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xsenc, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(len(stoi), len(stoi), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = xsenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/LLM/Shash-llm-from-scratch/llm/lib/python3.12/site-packages/matplotlib/pyplot.py:3562\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3543\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3560\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3561\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3562\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3571\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m     sci(__ret)\n\u001b[1;32m   3582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/Downloads/LLM/Shash-llm-from-scratch/llm/lib/python3.12/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Downloads/LLM/Shash-llm-from-scratch/llm/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5895\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5895\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5896\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/LLM/Shash-llm-from-scratch/llm/lib/python3.12/site-packages/matplotlib/image.py:729\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    728\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/LLM/Shash-llm-from-scratch/llm/lib/python3.12/site-packages/matplotlib/image.py:690\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_normalize_image_array\u001b[39m(A):\n\u001b[1;32m    686\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    Check validity of image-like input *A* and normalize it to a format suitable for\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m    Image subclasses.\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 690\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_masked_invalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    693\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverted to float\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/LLM/Shash-llm-from-scratch/llm/lib/python3.12/site-packages/matplotlib/cbook.py:733\u001b[0m, in \u001b[0;36msafe_masked_invalid\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_masked_invalid\u001b[39m(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 733\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39misnative:\n\u001b[1;32m    735\u001b[0m         \u001b[38;5;66;03m# If we have already made a copy, do the byteswap in place, else make a\u001b[39;00m\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;66;03m# copy with the byte order swapped.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;66;03m# Swap to native order.\u001b[39;00m\n\u001b[1;32m    738\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mbyteswap(inplace\u001b[38;5;241m=\u001b[39mcopy)\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnewbyteorder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/Downloads/LLM/Shash-llm-from-scratch/llm/lib/python3.12/site-packages/torch/_tensor.py:1083\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3209, 2.8249, 0.6830, 0.7708, 0.4068, 3.5116, 6.1745, 0.7929, 0.1641,\n",
       "         1.2725, 1.0774, 1.0867, 2.0655, 0.5166, 3.3497, 5.5673, 0.5504, 0.4182,\n",
       "         2.1804, 1.1062, 1.6890, 0.9447, 1.3622, 0.3811, 0.7179, 1.1966, 0.1623],\n",
       "        [0.4842, 0.7570, 0.5186, 0.5675, 0.8128, 0.7640, 1.2280, 1.9870, 0.2025,\n",
       "         1.4189, 7.6515, 1.5184, 0.4570, 2.2010, 4.7513, 0.3614, 1.3271, 0.1666,\n",
       "         1.0854, 1.1066, 0.2569, 0.6308, 0.7241, 8.1489, 7.9424, 1.0199, 0.8980],\n",
       "        [0.8382, 1.9532, 1.3001, 0.1803, 0.7093, 0.5697, 0.3943, 2.8374, 0.6202,\n",
       "         0.4323, 0.9129, 4.5527, 2.2208, 1.8152, 1.6362, 2.6333, 1.3689, 1.1638,\n",
       "         1.1663, 0.5607, 0.3926, 0.7776, 1.4241, 1.5881, 1.0215, 1.3093, 0.7558],\n",
       "        [0.8382, 1.9532, 1.3001, 0.1803, 0.7093, 0.5697, 0.3943, 2.8374, 0.6202,\n",
       "         0.4323, 0.9129, 4.5527, 2.2208, 1.8152, 1.6362, 2.6333, 1.3689, 1.1638,\n",
       "         1.1663, 0.5607, 0.3926, 0.7776, 1.4241, 1.5881, 1.0215, 1.3093, 0.7558],\n",
       "        [2.3917, 1.0144, 7.0778, 0.5202, 2.0818, 4.4831, 0.8444, 1.4605, 0.8095,\n",
       "         1.9117, 0.3063, 2.5730, 0.4823, 0.4862, 0.5396, 0.9668, 0.3148, 0.8824,\n",
       "         0.4844, 0.4206, 0.4264, 0.5823, 0.7825, 5.8371, 0.2922, 0.6639, 1.4137]],\n",
       "       grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0078, 0.0684, 0.0165, 0.0187, 0.0099, 0.0850, 0.1495, 0.0192, 0.0040,\n",
       "         0.0308, 0.0261, 0.0263, 0.0500, 0.0125, 0.0811, 0.1348, 0.0133, 0.0101,\n",
       "         0.0528, 0.0268, 0.0409, 0.0229, 0.0330, 0.0092, 0.0174, 0.0290, 0.0039],\n",
       "        [0.0099, 0.0155, 0.0106, 0.0116, 0.0166, 0.0156, 0.0251, 0.0406, 0.0041,\n",
       "         0.0290, 0.1562, 0.0310, 0.0093, 0.0449, 0.0970, 0.0074, 0.0271, 0.0034,\n",
       "         0.0222, 0.0226, 0.0052, 0.0129, 0.0148, 0.1663, 0.1621, 0.0208, 0.0183],\n",
       "        [0.0239, 0.0556, 0.0370, 0.0051, 0.0202, 0.0162, 0.0112, 0.0808, 0.0177,\n",
       "         0.0123, 0.0260, 0.1296, 0.0632, 0.0517, 0.0466, 0.0749, 0.0390, 0.0331,\n",
       "         0.0332, 0.0160, 0.0112, 0.0221, 0.0405, 0.0452, 0.0291, 0.0373, 0.0215],\n",
       "        [0.0239, 0.0556, 0.0370, 0.0051, 0.0202, 0.0162, 0.0112, 0.0808, 0.0177,\n",
       "         0.0123, 0.0260, 0.1296, 0.0632, 0.0517, 0.0466, 0.0749, 0.0390, 0.0331,\n",
       "         0.0332, 0.0160, 0.0112, 0.0221, 0.0405, 0.0452, 0.0291, 0.0373, 0.0215],\n",
       "        [0.0597, 0.0253, 0.1767, 0.0130, 0.0520, 0.1119, 0.0211, 0.0365, 0.0202,\n",
       "         0.0477, 0.0076, 0.0642, 0.0120, 0.0121, 0.0135, 0.0241, 0.0079, 0.0220,\n",
       "         0.0121, 0.0105, 0.0106, 0.0145, 0.0195, 0.1457, 0.0073, 0.0166, 0.0353]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = counts / counts.sum(dim=1, keepdim=True) # Normalize called softmax output -> probabilities distribution\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biagram example 1: . -> e index 0 -> 5\n",
      "input to nn: 0\n",
      "output actual from nn: 5\n",
      "output probabilities: tensor([0.0078, 0.0684, 0.0165, 0.0187, 0.0099, 0.0850, 0.1495, 0.0192, 0.0040,\n",
      "        0.0308, 0.0261, 0.0263, 0.0500, 0.0125, 0.0811, 0.1348, 0.0133, 0.0101,\n",
      "        0.0528, 0.0268, 0.0409, 0.0229, 0.0330, 0.0092, 0.0174, 0.0290, 0.0039],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "output probabilities: 0.0850\n",
      "output log likelihood: -2.4646\n",
      "negative log likelihood: 2.4646\n",
      "biagram example 2: e -> m index 5 -> 13\n",
      "input to nn: 5\n",
      "output actual from nn: 13\n",
      "output probabilities: tensor([0.0099, 0.0155, 0.0106, 0.0116, 0.0166, 0.0156, 0.0251, 0.0406, 0.0041,\n",
      "        0.0290, 0.1562, 0.0310, 0.0093, 0.0449, 0.0970, 0.0074, 0.0271, 0.0034,\n",
      "        0.0222, 0.0226, 0.0052, 0.0129, 0.0148, 0.1663, 0.1621, 0.0208, 0.0183],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "output probabilities: 0.0449\n",
      "output log likelihood: -3.1027\n",
      "negative log likelihood: 3.1027\n",
      "biagram example 3: m -> m index 13 -> 13\n",
      "input to nn: 13\n",
      "output actual from nn: 13\n",
      "output probabilities: tensor([0.0239, 0.0556, 0.0370, 0.0051, 0.0202, 0.0162, 0.0112, 0.0808, 0.0177,\n",
      "        0.0123, 0.0260, 0.1296, 0.0632, 0.0517, 0.0466, 0.0749, 0.0390, 0.0331,\n",
      "        0.0332, 0.0160, 0.0112, 0.0221, 0.0405, 0.0452, 0.0291, 0.0373, 0.0215],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "output probabilities: 0.0517\n",
      "output log likelihood: -2.9630\n",
      "negative log likelihood: 2.9630\n",
      "biagram example 4: m -> a index 13 -> 1\n",
      "input to nn: 13\n",
      "output actual from nn: 1\n",
      "output probabilities: tensor([0.0239, 0.0556, 0.0370, 0.0051, 0.0202, 0.0162, 0.0112, 0.0808, 0.0177,\n",
      "        0.0123, 0.0260, 0.1296, 0.0632, 0.0517, 0.0466, 0.0749, 0.0390, 0.0331,\n",
      "        0.0332, 0.0160, 0.0112, 0.0221, 0.0405, 0.0452, 0.0291, 0.0373, 0.0215],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "output probabilities: 0.0556\n",
      "output log likelihood: -2.8897\n",
      "negative log likelihood: 2.8897\n",
      "biagram example 5: a -> . index 1 -> 0\n",
      "input to nn: 1\n",
      "output actual from nn: 0\n",
      "output probabilities: tensor([0.0597, 0.0253, 0.1767, 0.0130, 0.0520, 0.1119, 0.0211, 0.0365, 0.0202,\n",
      "        0.0477, 0.0076, 0.0642, 0.0120, 0.0121, 0.0135, 0.0241, 0.0079, 0.0220,\n",
      "        0.0121, 0.0105, 0.0106, 0.0145, 0.0195, 0.1457, 0.0073, 0.0166, 0.0353],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "output probabilities: 0.0597\n",
      "output log likelihood: -2.8181\n",
      "negative log likelihood: 2.8181\n",
      "average negative log likelihood: 2.8476\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    x = xs[i].item() #input\n",
    "    y = ys[i].item() #output\n",
    "    print(f'biagram example {i+1}: {itos[x]} -> {itos[y]} index {x} -> {y}')\n",
    "    print(f'input to nn: {x}')\n",
    "    print(f'output actual from nn: {y}')\n",
    "    print(f'output probabilities: {probs[i]}')\n",
    "    p = probs[i, y]\n",
    "    print(f'output probabilities: {p.item():.4f}')\n",
    "    logp = torch.log(p)\n",
    "    print(f'output log likelihood: {logp.item():.4f}')\n",
    "    nll = -logp\n",
    "    print(f'negative log likelihood: {nll.item():.4f}')\n",
    "    nlls[i] = nll\n",
    "avg_nll = nlls.mean()\n",
    "print(f'average negative log likelihood: {avg_nll.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.8476\n"
     ]
    }
   ],
   "source": [
    "loss = -probs[range(len(xs)), ys].log().mean()\n",
    "print(f'loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad = None # set the gradient to zero\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data -= 0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.8104\n"
     ]
    }
   ],
   "source": [
    "logits = xsenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "loss = -probs[range(len(xs)), ys].log().mean()\n",
    "print(f'loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs , ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1, ix2 = stoi[ch1], stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements: 228146\n"
     ]
    }
   ],
   "source": [
    "num = xs.nelement()\n",
    "print(f'number of elements: {num}')\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn(len(stoi), len(stoi), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss: 2.4833\n",
      "iteration 1, loss: 2.4832\n",
      "iteration 2, loss: 2.4832\n",
      "iteration 3, loss: 2.4832\n",
      "iteration 4, loss: 2.4831\n",
      "iteration 5, loss: 2.4831\n",
      "iteration 6, loss: 2.4831\n",
      "iteration 7, loss: 2.4830\n",
      "iteration 8, loss: 2.4830\n",
      "iteration 9, loss: 2.4830\n",
      "iteration 10, loss: 2.4830\n",
      "iteration 11, loss: 2.4829\n",
      "iteration 12, loss: 2.4829\n",
      "iteration 13, loss: 2.4829\n",
      "iteration 14, loss: 2.4829\n",
      "iteration 15, loss: 2.4828\n",
      "iteration 16, loss: 2.4828\n",
      "iteration 17, loss: 2.4828\n",
      "iteration 18, loss: 2.4828\n",
      "iteration 19, loss: 2.4828\n",
      "iteration 20, loss: 2.4827\n",
      "iteration 21, loss: 2.4827\n",
      "iteration 22, loss: 2.4827\n",
      "iteration 23, loss: 2.4827\n",
      "iteration 24, loss: 2.4827\n",
      "iteration 25, loss: 2.4826\n",
      "iteration 26, loss: 2.4826\n",
      "iteration 27, loss: 2.4826\n",
      "iteration 28, loss: 2.4826\n",
      "iteration 29, loss: 2.4826\n",
      "iteration 30, loss: 2.4826\n",
      "iteration 31, loss: 2.4825\n",
      "iteration 32, loss: 2.4825\n",
      "iteration 33, loss: 2.4825\n",
      "iteration 34, loss: 2.4825\n",
      "iteration 35, loss: 2.4825\n",
      "iteration 36, loss: 2.4825\n",
      "iteration 37, loss: 2.4824\n",
      "iteration 38, loss: 2.4824\n",
      "iteration 39, loss: 2.4824\n",
      "iteration 40, loss: 2.4824\n",
      "iteration 41, loss: 2.4824\n",
      "iteration 42, loss: 2.4824\n",
      "iteration 43, loss: 2.4824\n",
      "iteration 44, loss: 2.4823\n",
      "iteration 45, loss: 2.4823\n",
      "iteration 46, loss: 2.4823\n",
      "iteration 47, loss: 2.4823\n",
      "iteration 48, loss: 2.4823\n",
      "iteration 49, loss: 2.4823\n",
      "iteration 50, loss: 2.4823\n",
      "iteration 51, loss: 2.4823\n",
      "iteration 52, loss: 2.4822\n",
      "iteration 53, loss: 2.4822\n",
      "iteration 54, loss: 2.4822\n",
      "iteration 55, loss: 2.4822\n",
      "iteration 56, loss: 2.4822\n",
      "iteration 57, loss: 2.4822\n",
      "iteration 58, loss: 2.4822\n",
      "iteration 59, loss: 2.4822\n",
      "iteration 60, loss: 2.4821\n",
      "iteration 61, loss: 2.4821\n",
      "iteration 62, loss: 2.4821\n",
      "iteration 63, loss: 2.4821\n",
      "iteration 64, loss: 2.4821\n",
      "iteration 65, loss: 2.4821\n",
      "iteration 66, loss: 2.4821\n",
      "iteration 67, loss: 2.4821\n",
      "iteration 68, loss: 2.4821\n",
      "iteration 69, loss: 2.4820\n",
      "iteration 70, loss: 2.4820\n",
      "iteration 71, loss: 2.4820\n",
      "iteration 72, loss: 2.4820\n",
      "iteration 73, loss: 2.4820\n",
      "iteration 74, loss: 2.4820\n",
      "iteration 75, loss: 2.4820\n",
      "iteration 76, loss: 2.4820\n",
      "iteration 77, loss: 2.4820\n",
      "iteration 78, loss: 2.4820\n",
      "iteration 79, loss: 2.4819\n",
      "iteration 80, loss: 2.4819\n",
      "iteration 81, loss: 2.4819\n",
      "iteration 82, loss: 2.4819\n",
      "iteration 83, loss: 2.4819\n",
      "iteration 84, loss: 2.4819\n",
      "iteration 85, loss: 2.4819\n",
      "iteration 86, loss: 2.4819\n",
      "iteration 87, loss: 2.4819\n",
      "iteration 88, loss: 2.4819\n",
      "iteration 89, loss: 2.4819\n",
      "iteration 90, loss: 2.4819\n",
      "iteration 91, loss: 2.4818\n",
      "iteration 92, loss: 2.4818\n",
      "iteration 93, loss: 2.4818\n",
      "iteration 94, loss: 2.4818\n",
      "iteration 95, loss: 2.4818\n",
      "iteration 96, loss: 2.4818\n",
      "iteration 97, loss: 2.4818\n",
      "iteration 98, loss: 2.4818\n",
      "iteration 99, loss: 2.4818\n"
     ]
    }
   ],
   "source": [
    "for k  in range(100):\n",
    "    xsenc = F.one_hot(xs, num_classes=len(stoi)).float()\n",
    "    logits = xsenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()+ 0.01*W.pow(2).mean()\n",
    "    print(f'iteration {k}, loss: {loss.item():.4f}') \n",
    "    loss.backward()\n",
    "    W.data -= 50 * W.grad\n",
    "    W.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zy\n",
      "mallen\n",
      "ddealy\n",
      "kelen\n",
      "a\n",
      "sqwigh\n",
      "kh\n",
      "shannilman\n",
      "ah\n",
      "ya\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "for _ in range(10):\n",
    "    x = torch.tensor([0]) # start with '.'\n",
    "    for _ in range(10):\n",
    "        xenc = F.one_hot(x, num_classes=len(stoi)).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(dim=1)\n",
    "        y = torch.multinomial(probs[0], 1)\n",
    "        if y == 0:\n",
    "            break\n",
    "        print(itos[y.item()], end='')\n",
    "        x = y\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
