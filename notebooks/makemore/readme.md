
# Makemore

**Makemore** is a simple, hackable tool designed to generate text that mimics the style of a given input dataset. It takes one text file as input, where each line is assumed to be a separate training instance, and then generates more instances that are similar in style. Under the hood, Makemore is an autoregressive character-level language model, offering a wide range of models from bigrams to transformers (similar to those used in GPT).

For example, you can feed it a database of names, and Makemore will generate unique baby name ideas that sound like real names but are novel. Similarly, you could input a list of company names to generate new company name ideas or provide a list of valid Scrabble words to generate English-like babble.

This project is not intended to be a heavyweight library with a myriad of configurations. Instead, it's a single hackable file, designed primarily for educational purposes. The only requirement is PyTorch.

## Key Implementations

Makemore currently implements models inspired by several foundational papers:

- **Bigram**: One character predicts the next, using a lookup table of counts.
- **MLP**: Following *Bengio et al. 2003*.
- **CNN**: Inspired by *DeepMind WaveNet 2016* (work in progress).
- **RNN**: Based on *Mikolov et al. 2010*.
- **LSTM**: Following *Graves et al. 2014*.
- **GRU**: Based on *Kyunghyun Cho et al. 2014*.
- **Transformer**: Following *Vaswani et al. 2017*.

## Usage

Makemore comes with a sample dataset, `names.txt`, which contains the most common 32K baby names from SSA.gov for the year 2018. Here's a snippet of what the dataset looks like:

```
emma
olivia
ava
isabella
sophia
charlotte
...
```

To train a model with this dataset, you can use the following command:

```bash
$ python makemore.py -i names.txt -o names
```

The training progress, logs, and model will all be saved to the specified output directory (`names` in this example). The default model is a super tiny 200K parameter transformer. Many more training configurations are available; refer to the argparse options and the source code for more details.

Training can run on any hardwareâ€”no special requirements. It works on a MacBook Air, but if you have a GPU, training will be much faster. During training, the script periodically prints sample outputs. If you'd like to generate samples manually, use the `--sample-only` flag in a separate terminal:

```bash
$ python makemore.py -i names.txt -o names --sample-only
```

This command loads the best model so far and prints additional samples on demand. Here are some unique baby names generated by Makemore using the default settings:

```
dontell
khylum
camatena
aeriline
najlah
sherrith
ryel
irmi
taislee
mortaz
akarli
maxfelynn
biolett
zendy
laisa
halliliana
goralynn
brodynn
romima
chiyomin
loghlyn
melichae
mahmed
irot
helicha
besdy
ebokun
lucianno
```

## Have Fun!

Makemore is designed to be fun and educational, so feel free to explore, tweak, and enjoy the process of generating new text!

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.
